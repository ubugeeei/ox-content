/**
 * Full-text search functionality for Ox Content.
 *
 * Generates search index at build time and provides client-side search.
 */

import * as fs from 'fs/promises';
import * as path from 'path';
import type { SearchOptions, ResolvedSearchOptions, SearchDocument } from './types';

// Import Rust bindings
let oxContent: typeof import('@ox-content/napi') | null = null;

async function getOxContent() {
  if (!oxContent) {
    try {
      oxContent = await import('@ox-content/napi');
    } catch {
      console.warn('[ox-content] Native bindings not available, search disabled');
      return null;
    }
  }
  return oxContent;
}

/**
 * Resolves search options with defaults.
 */
export function resolveSearchOptions(
  options: SearchOptions | boolean | undefined
): ResolvedSearchOptions {
  if (options === false) {
    return {
      enabled: false,
      limit: 10,
      prefix: true,
      placeholder: 'Search documentation...',
      hotkey: '/',
    };
  }

  const opts = typeof options === 'object' ? options : {};

  return {
    enabled: opts.enabled ?? true,
    limit: opts.limit ?? 10,
    prefix: opts.prefix ?? true,
    placeholder: opts.placeholder ?? 'Search documentation...',
    hotkey: opts.hotkey ?? '/',
  };
}

/**
 * Collects all Markdown files from a directory.
 */
async function collectMarkdownFiles(dir: string): Promise<string[]> {
  const files: string[] = [];

  async function walk(currentDir: string) {
    try {
      const entries = await fs.readdir(currentDir, { withFileTypes: true });

      for (const entry of entries) {
        const fullPath = path.join(currentDir, entry.name);

        if (entry.isDirectory() && !entry.name.startsWith('.') && entry.name !== 'node_modules') {
          await walk(fullPath);
        } else if (entry.isFile() && entry.name.endsWith('.md')) {
          files.push(fullPath);
        }
      }
    } catch {
      // Ignore errors
    }
  }

  await walk(dir);
  return files;
}

/**
 * Builds the search index from Markdown files.
 */
export async function buildSearchIndex(
  srcDir: string,
  base: string
): Promise<string> {
  const napi = await getOxContent();

  if (!napi) {
    return JSON.stringify({ documents: [], index: {}, df: {}, avg_dl: 0, doc_count: 0 });
  }

  const files = await collectMarkdownFiles(srcDir);
  const documents: SearchDocument[] = [];

  for (const file of files) {
    try {
      const content = await fs.readFile(file, 'utf-8');
      const relativePath = path.relative(srcDir, file);
      const url = base + relativePath.replace(/\.md$/, '').replace(/\\/g, '/');
      const id = relativePath.replace(/\.md$/, '').replace(/\\/g, '/');

      // Use Rust bindings to extract search content (if available)
      const extractSearchContent = (napi as any).extractSearchContent;
      if (!extractSearchContent) {
        console.warn('[ox-content] Search not available: extractSearchContent not implemented');
        return '[]';
      }
      const doc = extractSearchContent(content, id, url, { gfm: true });

      documents.push({
        id: doc.id,
        title: doc.title,
        url: doc.url,
        body: doc.body,
        headings: doc.headings,
        code: doc.code,
      });
    } catch {
      // Skip files that can't be processed
    }
  }

  // Build the index using Rust bindings (if available)
  const buildSearchIndex = (napi as any).buildSearchIndex;
  if (!buildSearchIndex) {
    console.warn('[ox-content] Search not available: buildSearchIndex not implemented');
    return JSON.stringify(documents);
  }
  return buildSearchIndex(documents);
}

/**
 * Writes the search index to a file.
 */
export async function writeSearchIndex(
  indexJson: string,
  outDir: string
): Promise<void> {
  const indexPath = path.join(outDir, 'search-index.json');

  // Ensure output directory exists
  await fs.mkdir(outDir, { recursive: true });

  // Write the index
  await fs.writeFile(indexPath, indexJson, 'utf-8');
}

/**
 * Client-side search module code.
 * This is injected into the bundle as a virtual module.
 */
export function generateSearchModule(
  options: ResolvedSearchOptions,
  indexPath: string
): string {
  return `
// Search module generated by ox-content
const searchOptions = ${JSON.stringify(options)};

let searchIndex = null;
let indexPromise = null;

// Tokenizer for queries
function tokenizeQuery(text) {
  const tokens = [];
  let current = '';

  for (const char of text) {
    const isCjk = /[\\u4E00-\\u9FFF\\u3400-\\u4DBF\\u3040-\\u309F\\u30A0-\\u30FF\\uAC00-\\uD7AF]/.test(char);

    if (isCjk) {
      if (current) {
        tokens.push(current.toLowerCase());
        current = '';
      }
      tokens.push(char);
    } else if (/[a-zA-Z0-9_]/.test(char)) {
      current += char;
    } else if (current) {
      tokens.push(current.toLowerCase());
      current = '';
    }
  }

  if (current) {
    tokens.push(current.toLowerCase());
  }

  return tokens;
}

// BM25 scoring
function computeIdf(df, docCount) {
  return Math.log((docCount - df + 0.5) / (df + 0.5) + 1.0);
}

function getFieldBoost(field) {
  switch (field) {
    case 'Title': return 10.0;
    case 'Heading': return 5.0;
    case 'Body': return 1.0;
    case 'Code': return 0.5;
    default: return 1.0;
  }
}

// Load the index
async function loadIndex() {
  if (searchIndex) return searchIndex;
  if (indexPromise) return indexPromise;

  indexPromise = fetch('${indexPath}')
    .then(res => res.json())
    .then(data => {
      searchIndex = data;
      return data;
    })
    .catch(err => {
      console.error('[ox-content] Failed to load search index:', err);
      return null;
    });

  return indexPromise;
}

// Search function
export async function search(query, options = {}) {
  const index = await loadIndex();

  if (!index || !query.trim()) {
    return [];
  }

  const limit = options.limit ?? searchOptions.limit;
  const prefix = options.prefix ?? searchOptions.prefix;
  const tokens = tokenizeQuery(query);

  if (tokens.length === 0) {
    return [];
  }

  const k1 = 1.2;
  const b = 0.75;
  const docScores = new Map();

  for (let i = 0; i < tokens.length; i++) {
    const token = tokens[i];
    const isLast = i === tokens.length - 1;

    // Find matching terms
    let matchingTerms = [];
    if (prefix && isLast && token.length >= 2) {
      matchingTerms = Object.keys(index.index).filter(term => term.startsWith(token));
    } else if (index.index[token]) {
      matchingTerms = [token];
    }

    for (const term of matchingTerms) {
      const postings = index.index[term] || [];
      const df = index.df[term] || 1;
      const idf = computeIdf(df, index.doc_count);

      for (const posting of postings) {
        const doc = index.documents[posting.doc_idx];
        if (!doc) continue;

        const docLen = doc.body.length;
        const tf = posting.tf;
        const boost = getFieldBoost(posting.field);

        const score = idf * ((tf * (k1 + 1.0)) / (tf + k1 * (1.0 - b + b * docLen / index.avg_dl))) * boost;

        if (!docScores.has(posting.doc_idx)) {
          docScores.set(posting.doc_idx, { score: 0, matches: new Set() });
        }
        const entry = docScores.get(posting.doc_idx);
        entry.score += score;
        entry.matches.add(term);
      }
    }
  }

  // Convert to results
  const results = Array.from(docScores.entries())
    .map(([docIdx, data]) => {
      const doc = index.documents[docIdx];
      const matches = Array.from(data.matches);

      // Generate snippet
      let snippet = '';
      if (doc.body) {
        const bodyLower = doc.body.toLowerCase();
        let firstPos = -1;
        for (const match of matches) {
          const pos = bodyLower.indexOf(match);
          if (pos !== -1 && (firstPos === -1 || pos < firstPos)) {
            firstPos = pos;
          }
        }

        const start = Math.max(0, firstPos - 50);
        const end = Math.min(doc.body.length, start + 150);
        snippet = doc.body.slice(start, end);
        if (start > 0) snippet = '...' + snippet;
        if (end < doc.body.length) snippet = snippet + '...';
      }

      return {
        id: doc.id,
        title: doc.title,
        url: doc.url,
        score: data.score,
        matches,
        snippet,
      };
    })
    .sort((a, b) => b.score - a.score)
    .slice(0, limit);

  return results;
}

export { searchOptions };
export default { search, searchOptions, loadIndex };
`;
}
